# Decision Forge AI – System Architecture Overview

## Purpose

Decision Forge AI is a structured human risk simulation platform designed to evaluate and strengthen cybersecurity decision-making under adversarial conditions.

The system models phishing, credential misuse, social engineering, and operational security dilemmas across diverse professional environments. It integrates controlled assessment, contextual personalization, and measurable performance analysis within a research-aligned evaluation framework.

---

## Architectural Philosophy

Decision Forge AI operates through two integrated control layers:

1. Contextual Personalization Layer  
2. Evaluation Integrity Layer  

The Personalization Layer dynamically adapts scenario context to a participant’s selected profession or operational environment.

The Evaluation Integrity Layer enforces structural consistency, scoring invariance, anti-priming safeguards, and experimental control.

This separation preserves realism while maintaining methodological rigor.

---

## Core Evaluation Flow

Decision Forge AI follows a fixed three-phase sequence:

1. Baseline Assessment  
2. Adversarial Simulation Phase  
3. Reassessment  

The sequence is invariant.  
Structural reordering or bypassing of phases is not permitted.

This fixed progression ensures measurement consistency across sessions.

---

## Contextual Personalization

At session initiation, participants provide their profession, role, or operational environment.

Examples include:

- Healthcare  
- Education  
- Finance  
- Retail  
- Government  
- Technology  
- Small Business  
- Custom user-defined roles  

Scenarios are dynamically framed to reflect realistic threat vectors within the participant’s domain.

While contextual framing varies, evaluation structure and scoring logic remain identical across tracks.

---

## Evaluation Model

### Baseline Assessment

- 5 scenario-based decision prompts  
- 10 points per prompt  
- Maximum score: 50  
- No feedback during evaluation  
- No priming language or titled cues  

Purpose: Establish unassisted adversarial detection capability.

---

### Adversarial Simulation Phase

- 10 contextualized adversarial scenarios  
- 10 points per scenario  
- Maximum score: 100  
- Immediate explanatory reinforcement  

Purpose: Reinforce disciplined reasoning, least-privilege alignment, and risk recognition under simulated pressure.

Dynamic explanation is permitted during this phase. Scoring structure remains fixed.

---

### Reassessment

- 5 scenario-based decision prompts  
- 10 points per prompt  
- Maximum score: 50  
- Distinct from baseline  
- Comparable difficulty  
- No priming language  

Purpose: Measure knowledge transfer and behavioral improvement.

Improvement Delta = Reassessment Score – Baseline Score  
Range: -50 to +50

---

## Behavioral Scoring Engine

- Correct response: 10 points  
- Incorrect response: 0 points  
- No negative scoring  
- No partial credit  

The scoring framework is invariant across professions and sessions to preserve comparability.

---

## Anti-Priming Controls

To maintain evaluation validity:

- Baseline and reassessment prompts are untitled  
- Topic categories are not revealed  
- No thematic hints are provided  
- Feedback is withheld during formal assessment phases  

Dynamic interaction is limited to the simulation phase only.

---

## Session Discipline

Decision Forge AI maintains structured progression control.

The system:

- Redirects off-topic responses  
- Prevents structural deviation  
- Maintains evaluation sequence integrity  
- Terminates only upon explicit participant request  

---

## Reflection and Reinforcement

Following reassessment, participants complete structured reflection.

The system provides a personalized synthesis highlighting:

- Improvement in adversarial detection  
- Growth in disciplined response selection  
- Increased confidence in risk evaluation  
- Areas for continued reinforcement  

This phase strengthens retention beyond quantitative scoring.

---

## Data Handling and Privacy

Decision Forge AI:

- Does not store personal identifiers  
- Does not retain cross-session memory  
- Does not collect unnecessary demographic data  
- Requires participants to self-record scores externally  

Only anonymized summary metrics are documented outside the live environment.

---

## Intellectual Property Notice

This repository documents system architecture, evaluation structure, and scoring methodology.

Detailed prompt engineering logic, internal guardrails, adversarial scenario design, and operational control instructions are proprietary and are not included in this repository.
