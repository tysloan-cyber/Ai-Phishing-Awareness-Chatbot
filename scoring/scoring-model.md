# Methodology – CyberQuest Evaluation (v2)

## Purpose
Evaluate whether a short, scenario-based chatbot experience improves phishing and social engineering detection in realistic contexts.

## Study Design
Pre/post design with an instructional intervention.

- Baseline quiz: 5 questions (10 points each; max 50)
- Storyline mission: 10 scenes (10 points each; max 100)
- Reassessment quiz: 5 questions (10 points each; max 50)

Baseline and reassessment use **different** question sets of comparable difficulty to reduce memorization effects and better measure learning transfer.

## Participant Flow
1. Participant completes baseline quiz (5 items).
2. Participant completes the interactive storyline (10 scenes with feedback).
3. Participant completes reassessment quiz (5 items).
4. Participant records scores and submits feedback survey.

## Scoring
- Correct response: 10 points
- Incorrect response: 0 points
- No partial credit (Version 1)

Primary outcome metric:
- Improvement Delta = Reassessment Score – Baseline Score (range: -50 to +50)

Secondary metrics (optional):
- Baseline % and Reassessment %
- Storyline % (engagement/progression indicator)

## Content Variants
Two storyline variants are available:
- Healthcare Worker: “The Double Shift: A Hospital Cyber Crisis”
- Student: “Campus Clickbait: The Cyber Semester”

Each includes:
- 5 baseline questions
- 10 storyline scenes
- 5 reassessment questions
with consistent scoring rules.

## Data Collection
Participants submit:
- Baseline score (0–50)
- Storyline score (0–100)
- Reassessment score (0–50)
- Optional confidence rating (1–5)
- Brief qualitative reflection (what felt tricky, what they learned)

Raw conversation logs are not required for scoring and are not stored in the public repository.

## Threats to Validity (Noted)
- Small sample sizes can limit generalizability.
- Participants may differ in prior cybersecurity exposure.
- Differences in reading speed/device context may influence performance.
