# CyberQuest Scoring Model

## Overview

CyberQuest uses a controlled three-phase evaluation structure:

1. Baseline Assessment (Pre-Test)
2. Storyline Training Phase
3. Reassessment (Post-Test)

Scenarios are dynamically tailored to the participant’s selected profession or role. However, scoring structure and assessment format remain consistent across all professions.

---

## Scoring Rules

Each scored question is worth:

- Correct answer: 10 points
- Incorrect answer: 0 points

No partial credit.  
No negative scoring.

These rules never change across professions.

---

## Assessment Structure

### Baseline (Pre-Test)

- 5 scenario-based questions
- 10 points per question
- Maximum score: 50
- No feedback during baseline
- No priming or titled questions
- No explanation until completion

Purpose: Measure initial cybersecurity detection ability.

---

### Storyline Training

- 10 scenario-based interactions
- 10 points per scenario
- Maximum score: 100
- Immediate feedback after each response
- Dynamic explanation allowed
- Profession-specific context

Purpose: Provide immersive learning and reinforcement.

---

### Reassessment (Post-Test)

- 5 scenario-based questions
- 10 points per question
- Maximum score: 50
- Different questions from baseline
- Comparable difficulty
- No priming or titled questions
- No feedback until completion

Purpose: Measure learning transfer.

---

## Improvement Metric

Improvement Delta = Reassessment Score – Baseline Score

Range: -50 to +50

Interpretation:

- Positive value = Improvement
- Zero = No measurable change
- Negative value = Performance decrease

---

## Percentage Calculation

Baseline % = (Baseline ÷ 50) × 100  
Storyline % = (Storyline ÷ 100) × 100  
Reassessment % = (Reassessment ÷ 50) × 100  

---

## Profession-Based Personalization

Scenario content is dynamically tailored to the participant’s selected profession.

Examples may include:
- Healthcare
- Education
- Finance
- Retail
- Government
- Technology
- Small Business
- Other user-defined roles

While content varies by profession, scoring structure remains identical across tracks.

---

## Research Controls

To preserve experimental integrity:

- Baseline and reassessment are untitled and non-priming.
- Feedback is withheld during assessments.
- Scoring rules are fixed.
- No adaptive retesting is used during evaluation.
- Dynamic presentation is limited to the training phase.
- Participants self-record scores externally.

---

## Data Handling

CyberQuest does not store:
- Personal identifiers
- Cross-session memory
- Participant score history

All data collection occurs externally via structured participant reporting.
